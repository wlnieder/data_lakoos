{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging daily files into one file and creating counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to merge all the files containing the tweets filtered according to a keyword into one file and then creating a count. This code produces a daily as well as an hourly count. For our project we ended up using only the daily count, as it had to match the Binance and Google Trend data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through my files and merge them according to the keyword \n",
    "\n",
    "def merging_total(keyword):\n",
    "    # I left my real file names in here, because I think it makes it easier to understand the structure of the function\n",
    "    # and why I decided to write it as it is\n",
    "    \n",
    "    # Reading in the first keyword file and creating a dataframe of it\n",
    "    df= pd.read_csv('ukraine_russia-2022-02-24_'+keyword+'.csv', header=[0])\n",
    "    \n",
    "    file_start= 'ukraine_russia-2022-'\n",
    "    month_02 = '02-'  # for the February files\n",
    "    \n",
    "    # I read in the first file and extend the data from the second file on\n",
    "    # My files start on the 24th, so i append from the second file on (the 25th)\n",
    "    i = 25\n",
    "    \n",
    "    while i<29:\n",
    "        file=file_start+month_02+str(i)+'_'+keyword+'.csv'\n",
    "        df_add=pd.read_csv(file, header=[0])\n",
    "        df = pd.concat([df, df_add], ignore_index=True)\n",
    "        i+=1\n",
    "    \n",
    "    month_03 = '03-' # for the March files\n",
    "    m = 1\n",
    "    \n",
    "    # Because my files use dates with the days numbered as 01, 02, 03 and so on I used two while loops\n",
    "    # as the loop goes 1, 2, 3, ..., 9 and not 01, 02, 03, ..., 09\n",
    "    while m < 10:\n",
    "        file=file_start+month_03+'0'+str(m)+'_'+keyword+'.csv' # adding the 0 in front of m to match the files\n",
    "        df_add=pd.read_csv(file, header=[0])\n",
    "        df = pd.concat([df, df_add], ignore_index=True)\n",
    "        m+=1\n",
    "    \n",
    "    # from the 10. on, there is no need for the added 0 anymore\n",
    "    while m<25:\n",
    "        file=file_start+month_03+str(m)+'_'+keyword+'.csv' \n",
    "        df_add=pd.read_csv(file, header=[0])\n",
    "        df = pd.concat([df, df_add], ignore_index=True)\n",
    "        m+=1\n",
    "    \n",
    "    return df   \n",
    "        \n",
    "    # this function returns a dataframe with all tweets containing the chosen keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_start = 'ukraine_russia_total_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Tweets: Humanitarian Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humanitarian_crisis = merging_total('humanitarian_crisis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humanitarian_crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the column with the old indexes\n",
    "df_humanitarian_crisis = df_humanitarian_crisis.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humanitarian_crisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a count: Humanitarian Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humanitarian_crisis.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting created_at column to datetime data type\n",
    "# This allows me to use datetime related functions, that make further processing easier\n",
    "df_humanitarian_crisis['created_at'] = pd.to_datetime(df_humanitarian_crisis['created_at'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humanitarian_crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add one column for the date and hour they were created and one column that only contains the day\n",
    "def adding_hour_and_day_column(df_input):\n",
    "    # Creating an hour column for hourly count\n",
    "    df_input['created_at_hour'] = pd.to_datetime(df_input['created_at'].apply(str).str[:-12])\n",
    "    # Creating a day columnd for daily count\n",
    "    df_input['created_at_day'] = pd.to_datetime(df_input['created_at']).dt.date\n",
    "    \n",
    "    return df_input\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humanitarian_crisis = adding_hour_and_day_column(df_humanitarian_crisis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humanitarian_crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create dataframe with hourly count\n",
    "def create_hour_count(df, keyword):\n",
    "    df_hour_count = pd.DataFrame(df.groupby('created_at_hour').size())\n",
    "    # This renames the count column after the keyword used\n",
    "    df_hour_count.rename(columns={0: 'count_'+keyword}, inplace = True)\n",
    "    \n",
    "    return df_hour_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create dataframe with day count and rename the column with count (just as above)\n",
    "def create_day_count(df, keyword):\n",
    "    df_day_count = pd.DataFrame(df.groupby('created_at_day').size())\n",
    "    df_day_count.rename(columns={0: 'count_'+keyword}, inplace = True)\n",
    "    \n",
    "    return df_day_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_hc = create_hour_count(df_humanitarian_crisis, 'humanitarian_crisis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_hc = create_day_count(df_humanitarian_crisis, 'humanitarian_crisis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Tweets: Invasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invasion = merging_total('invasion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the column with the old indexes\n",
    "df_invasion = df_invasion.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invasion['created_at'] = pd.to_datetime(df_invasion['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invasion.to_csv(output_file_start+'invasion.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a count: Invasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invasion = adding_hour_and_day_column(df_invasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_invasion = create_hour_count(df_invasion, 'invasion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_invasion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see here, that there are some leftover tweets from 2022-02-23 23:00:00. They have to be dropped, as they don't belong to the defined time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_invasion = df_count_hour_invasion.drop('2022-02-23 23:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_invasion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it only contains the data it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_invasion = create_day_count(df_invasion, 'invasion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_invasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I have to drop 2022-02-23 for the same reasons. Here I just drop the first row by leaving out\n",
    "df_count_day_invasion = df_count_day_invasion[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_invasion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Tweets: Sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanction = merging_total('sanction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the column with the old indexes\n",
    "df_sanction = df_sanction.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanction['created_at'] = pd.to_datetime(df_sanction['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanction.to_csv(output_file_start+'sanction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a count: Sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanction = adding_hour_and_day_column(df_sanction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_sanction = create_hour_count(df_sanction, 'sanction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm having the same problem with some excess data from 23 February, which needs to be dropped\n",
    "df_count_hour_sanction = df_count_hour_sanction.drop('2022-02-23 23:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that there is only the data left I need\n",
    "df_count_hour_sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_sanction = create_day_count(df_sanction, 'sanction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_sanction = df_count_day_sanction.drop(df_count_day_sanction.index[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_sanction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Tweets: War"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_war = merging_total('war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the column with the old indexes\n",
    "df_war = df_war.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_war['created_at'] = pd.to_datetime(df_war['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_war.to_csv(output_file_start+'war.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a count: War"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_war = adding_hour_and_day_column(df_war)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_war = create_hour_count(df_war, 'war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_war = df_count_hour_war.drop('2022-02-23 23:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_hour_war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_war = create_day_count(df_war, 'war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_war = df_count_day_war.drop(df_count_day_war.index[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_day_war"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging hourly and daily counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are te hourly and daily dataframes I created:  \n",
    "\n",
    "df_count_hour_hc  \n",
    "df_count_hour_invasion   \n",
    "df_count_hour_sanction   \n",
    "df_count_hour_war   \n",
    "\n",
    "     \n",
    "     \n",
    "df_count_day_hc  \n",
    "df_count_day_invasion  \n",
    "df_count_day_sanction  \n",
    "df_count_day_war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the hourly dataframes\n",
    "df_hour_total = pd.concat([df_count_hour_hc, df_count_hour_invasion, df_count_hour_sanction, df_count_hour_war], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if it is complete\n",
    "df_hour_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it as a csv\n",
    "df_hour_total.to_csv(output_file_start+'count_hour.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the daily dataframes\n",
    "df_day_total = pd.concat([df_count_day_hc, df_count_day_invasion, df_count_day_sanction, df_count_day_war], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if it is complete\n",
    "df_day_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it as a csv\n",
    "df_day_total.to_csv(output_file_start+'count_day.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
